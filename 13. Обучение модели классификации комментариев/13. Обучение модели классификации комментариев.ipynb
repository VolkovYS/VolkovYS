{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель:-Логистическая-регрессия\" data-toc-modified-id=\"Модель:-Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Модель: Логистическая регрессия</a></span></li><li><span><a href=\"#Модель:LGBMClassifier\" data-toc-modified-id=\"Модель:LGBMClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Модель:LGBMClassifier</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Проверка-на-тесте\" data-toc-modified-id=\"Проверка-на-тесте-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Проверка на тесте</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель:-Логистическая-регрессия\" data-toc-modified-id=\"Модель:-Логистическая-регрессия-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Модель: Логистическая регрессия</a></span></li><li><span><a href=\"#Модель:LGBMClassifier\" data-toc-modified-id=\"Модель:LGBMClassifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Модель:LGBMClassifier</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/datasets/toxic_comments.csv\") #Выведем таблицу на экран\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 80.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(memory_usage='deep') #Посмотрим информацию о таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:solid green 2px; padding: 10px\">\n",
    "    \n",
    "159571 строка\n",
    "<br>Дубликатов и пропусков нет\n",
    "<br>2 столбца: toxic, text\n",
    "<br>90% твитов не токсичны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): #Функция для обработки английского текста\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 73.7 ms, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>and i really do not think you understand i cam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation why the edits made under my userna...      0\n",
       "1       d aww he matches this background colour i am s...      0\n",
       "2       hey man i am really not trying to edit war it ...      0\n",
       "3       more i cannot make any real suggestions on imp...      0\n",
       "4       you sir are my hero any chance you remember wh...      0\n",
       "...                                                   ...    ...\n",
       "159566  and for the second time of asking when your vi...      0\n",
       "159567  you should be ashamed of yourself that is a ho...      0\n",
       "159568  spitzer umm theres no actual article for prost...      0\n",
       "159569  and it looks like it was actually you who put ...      0\n",
       "159570  and i really do not think you understand i cam...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные подготовлены и обработаны. В данных 2 столбца (toxic, text), 159571 строка. Дубликатов и пропусков нет. 90% твитов не токсичны.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('toxic', axis=1)\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111699, 1)\n",
      "(47872, 1)\n",
      "(111699,)\n",
      "(47872,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=12345)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель: Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "0.7757764993912689\n",
      "CPU times: user 12min 56s, sys: 10min 55s, total: 23min 52s\n",
      "Wall time: 23min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression(random_state=12345))])\n",
    "\n",
    "params = {'clf__C': [0.1, 1, 10, 100],\n",
    "          'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "lr_grid.fit(X_train['text'], y_train)\n",
    "lr_best_paramms = lr_grid.best_params_\n",
    "\n",
    "print(lr_best_paramms)\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель:LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__learning_rate': 0.25, 'clf__max_depth': -1, 'clf__n_estimators': 200}\n",
      "0.7686050343448693\n",
      "CPU times: user 5h 24min 52s, sys: 2min 37s, total: 5h 27min 29s\n",
      "Wall time: 5h 29min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LGBMClassifier(random_state=12345))])\n",
    "\n",
    "params = {\n",
    "  'clf__n_estimators': [200],\n",
    "  'clf__learning_rate': [0.15, 0.25],\n",
    "  'clf__max_depth': [ 10, -1]}\n",
    "\n",
    "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "lgb_grid.fit(X_train['text'], y_train)\n",
    "lgb_best_params = lgb_grid.best_params_\n",
    "\n",
    "print(lgb_best_params)\n",
    "print(lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression on train: 0.7757764993912689\n",
    "<br>LGBMClassifier on train: 0.7686050343448693"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(ngram_range=(1,3),\n",
    "               min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize.fit_transform(X_train['text'])\n",
    "X_test = vectorize.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(fitted_model):\n",
    "    test_pred = fitted_model.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "    print('F1 on test: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель: Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test: 0.784\n"
     ]
    }
   ],
   "source": [
    "lr_m = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
    "lr_m.fit(X_train, y_train)\n",
    "scoring(lr_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель:LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test: 0.778\n"
     ]
    }
   ],
   "source": [
    "lgb_m = LGBMClassifier(learning_rate=0.25, max_depth=-1, n_estimators=200, random_state = 12345)\n",
    "lgb_m.fit(X_train, y_train)\n",
    "scoring(lgb_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression on test: 0.784\n",
    "<br>LGBMClassifier on test: 0.778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 5px; padding: 20px\">\n",
    "    \n",
    "**<font color=\"green\">Подготовка</font>**\n",
    "<br> Данные подготовлены и обработаны. В данных 2 столбца (toxic, text), 159571 строка. Дубликатов и пропусков нет. 90% твитов не токсичны.\n",
    "    \n",
    "**<font color=\"green\">Обучение</font>**\n",
    "<br>LogisticRegression on train: 0.7757764993912689\n",
    "<br>LGBMClassifier on train: 0.7686050343448693\n",
    "    \n",
    "**<font color=\"green\">Проверка на тесте</font>**\n",
    "<br>LogisticRegression on test: 0.784\n",
    "<br>LGBMClassifier on test: 0.778\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 423,
    "start_time": "2022-07-01T16:01:11.646Z"
   },
   {
    "duration": 3274,
    "start_time": "2022-07-01T16:01:39.641Z"
   },
   {
    "duration": 1599,
    "start_time": "2022-07-01T16:17:19.802Z"
   },
   {
    "duration": 787,
    "start_time": "2022-07-01T16:17:41.632Z"
   },
   {
    "duration": 61,
    "start_time": "2022-07-01T16:18:06.929Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-01T16:18:24.653Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-01T16:25:36.762Z"
   },
   {
    "duration": 8809,
    "start_time": "2022-07-01T16:25:54.761Z"
   },
   {
    "duration": 32,
    "start_time": "2022-07-01T16:26:05.979Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-01T16:26:10.642Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-01T18:23:26.010Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-01T18:23:55.782Z"
   },
   {
    "duration": 13195,
    "start_time": "2022-07-01T18:24:02.707Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-01T18:25:04.490Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-01T18:29:21.114Z"
   },
   {
    "duration": 25,
    "start_time": "2022-07-01T18:29:31.482Z"
   },
   {
    "duration": 39,
    "start_time": "2022-07-01T18:30:30.171Z"
   },
   {
    "duration": 163,
    "start_time": "2022-07-01T18:30:47.597Z"
   },
   {
    "duration": 40,
    "start_time": "2022-07-01T18:30:59.732Z"
   },
   {
    "duration": 1433950,
    "start_time": "2022-07-01T18:32:09.338Z"
   },
   {
    "duration": 19740675,
    "start_time": "2022-07-01T18:56:03.290Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-02T00:25:03.966Z"
   },
   {
    "duration": 27494,
    "start_time": "2022-07-02T00:25:03.971Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-02T00:26:32.345Z"
   },
   {
    "duration": 59814,
    "start_time": "2022-07-02T00:26:32.350Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-02T00:27:32.248Z"
   },
   {
    "duration": 560401,
    "start_time": "2022-07-02T03:33:02.105Z"
   },
   {
    "duration": 64252,
    "start_time": "2022-07-02T03:42:22.509Z"
   },
   {
    "duration": 51,
    "start_time": "2022-07-02T12:56:36.919Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
